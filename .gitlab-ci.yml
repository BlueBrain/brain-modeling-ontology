image: python:3.8

include:
  - project: cs/gitlabci-templates
    file: /build-image-using-kaniko.yml

stages:
  - test
  - register
  - generate
  - deploy

# TEST STAGE

# It runs only when a push is executed in a merge request and an ontology file has changed
# or when a commit is executed in develop branch and an ontology file has changed
# or when a new tag is pushed
test-ontologies-on-merge-request:
  stage: test
  rules:
    - if: '$CI_PIPELINE_SOURCE == "merge_request_event"'
      when: always
    - if: '$CI_PIPELINE_SOURCE == "push" && $CI_COMMIT_BRANCH == "develop"'
      when: always
    - if: $CI_COMMIT_TAG
      when: always
  script:
    - pytest tests/test_ontologies.py --atlas_parcellation_ontology_version 54 --token $NEXUS_TOKEN_STAGING
  before_script:
    - pip install -r requirements.txt
variables:
  KUBERNETES_HELPER_MEMORY_REQUEST: 512Mi
  KUBERNETES_HELPER_MEMORY_LIMIT: 1Gi
#    KUBERNETES_MEMORY_LIMIT: 8Gi
#    KUBERNETES_MEMORY_REQUEST: 8Gi


# REGISTER STAGE

# It runs only when a commit is done on develop branch and the pipeline was triggered from a Merge Request
# and an ontology file has changed
register-on-staging-environment:
  stage: register
  rules:
    - if: '$CI_PIPELINE_SOURCE == "push" && $CI_COMMIT_BRANCH == "develop"'
      changes:
          - ontologies/bbp/*.ttl
          - shapes/**/*.json
          - jsonldcontext/*.json
          - texts/*.json
          - register_ontologies.py
          - bmo/ontologies.py
          - bmo/utils.py
      when: on_success
  script:
    - python register_ontologies.py --environment staging --bucket neurosciencegraph/datamodels --ontology_dir './ontologies/bbp/*.ttl' --schema_dir './shapes/**/*.json' --atlas_parcellation_ontology https://bbp.epfl.ch/neurosciencegraph/data/ontologies/34388d3b-0b88-4deb-9686-6fcd9ef8990e --atlas_parcellation_ontology_bucket bbp/atlas --atlas_parcellation_ontology_version 54 --token $NEXUS_TOKEN_STAGING
  before_script:
    - pip install -r requirements.txt

# It runs only when a new tag is pushed.
# It executes ontologies registration for the files changed between this version and the previous one
register-on-production-environment:
  stage: register
  rules:
    - if: $CI_COMMIT_TAG
      when: on_success
  script:
    - echo $CI_COMMIT_TAG
    - python register_ontologies.py --environment production --bucket neurosciencegraph/datamodels --ontology_dir './ontologies/bbp/*.ttl' --schema_dir './shapes/**/*.json' --atlas_parcellation_ontology https://bbp.epfl.ch/neurosciencegraph/data/0518dd0b-cbc7-43ef-a75f-45631059c8c5 --atlas_parcellation_ontology_bucket bbp/atlas --atlas_parcellation_ontology_version 9 --token $NEXUS_TOKEN_PRODUCTION --tag $CI_COMMIT_TAG
  before_script:
    - pip install -r requirements.txt

# GENERATE STAGE

# Building documentation for sphinx and ontodocs
# The docs are generated and stored in artifacts in order to be used in the deploy stage

# Generate ontodocs documentation files and store them in
generate-ontodocs-documentation:
  stage: generate
  image: python:3.8
  rules:
    - if: '$CI_PIPELINE_SOURCE == "push" && $CI_COMMIT_BRANCH == "develop"'
      when: on_success
      variables:
        CLUSTER_NAME: dev_cluster
        K8S_SERVER: https://kubernetesdev.bbp.epfl.ch:6443
        SA_TOKEN: $SA_TOKEN_DEVELOPMENT
        K8S_CA: ".kube/ca-dev.crt"
    - if: $CI_COMMIT_TAG
      when: on_success
      variables:
        CLUSTER_NAME: prod_cluster
        K8S_SERVER: https://kubernetes.bbp.epfl.ch:6443/
        SA_TOKEN: $SA_TOKEN_PRODUCTION
        K8S_CA: ".kube/ca-prod.crt"
  before_script:
    - curl -LO "https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl"
    - chmod +x kubectl
    - mkdir -p ~/.local/bin
    - mv ./kubectl ~/.local/bin/kubectl
    - pip install git+https://$GITLAB_DEPLOY_TOKEN:$GITLAB_DEPLOY_PASSWORD@bbpgitlab.epfl.ch/dke/apps/ontodocs.git
  script:
    - mkdir visualization
    - ontospy gendocs ./ontologies/bbp --theme lumen --outputpath ./visualization --title "Brain Modeling Ontology" --preflabel "label" -v
    - ~/.local/bin/kubectl config set-cluster $CLUSTER_NAME --server=$K8S_SERVER --certificate-authority=$K8S_CA
    - ~/.local/bin/kubectl config set-context $CLUSTER_NAME --cluster=$CLUSTER_NAME
    - ~/.local/bin/kubectl config set-credentials pod-creator-ci --token=$SA_TOKEN
    - ~/.local/bin/kubectl config set-context $CLUSTER_NAME --user=pod-creator-ci
    - ~/.local/bin/kubectl config use-context $CLUSTER_NAME
    - POD=$(~/.local/bin/kubectl get pods -n bbp-ou-dke --selector=app=bmo-ontodocs -o=jsonpath="{.items[*].metadata.name}" | cut -d ' ' -f 1)
    - ~/.local/bin/kubectl cp ./visualization/. "$POD:/usr/share/nginx/html/" -n bbp-ou-dke --no-preserve
  variables:
    KUBERNETES_MEMORY_LIMIT: 4Gi
    KUBERNETES_MEMORY_REQUEST: 4Gi


# Generate sphinx documentation and stores the artifact under /generated/html
generate-sphinx-documentation:
  stage: generate
  image: python:3.8
  rules:
    - if: '$CI_PIPELINE_SOURCE == "push" && $CI_COMMIT_BRANCH == "develop"'
      when: on_success
    - if: $CI_COMMIT_TAG
      when: on_success
  script:
    - pip install .[docs]
    - sphinx-build -T --keep-going -b html -d _build/doctrees -c ./docs/source -D language=en ./docs/source generated/html
  artifacts:
    paths:
      - generated/html
  variables:
    KUBERNETES_MEMORY_LIMIT: 4Gi
    KUBERNETES_MEMORY_REQUEST: 4Gi

# DEPLOY STAGE

# Executes deployment of project documentation
deploy-sphinx-documentation:
  stage: deploy
  extends: .build-image-using-kaniko
  dependencies:
    - generate-sphinx-documentation
  rules:
    - if: '$CI_PIPELINE_SOURCE == "push" && $CI_COMMIT_BRANCH == "develop"'
      when: on_success
      variables:
        CI_REGISTRY_IMAGE: $CI_REGISTRY_IMAGE/sphinx-documentation-staging
    - if: $CI_COMMIT_TAG
      when: on_success
      variables:
        CI_REGISTRY_IMAGE: $CI_REGISTRY_IMAGE/sphinx-documentation-production
  variables:
    KANIKO_EXTRA_ARGS: "--build-arg GENERATED_DOCS_PATH=generated/html"
    CI_COMMIT_SHORT_SHA: $CI_COMMIT_SHORT_SHA
    REGISTRY_IMAGE_TAG: $CI_COMMIT_SHORT_SHA-$(date +%s)
    KUBERNETES_MEMORY_LIMIT: 4Gi
    KUBERNETES_MEMORY_REQUEST: 4Gi